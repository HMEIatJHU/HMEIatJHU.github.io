---
layout: page
permalink: /recruitment/
title: recruitment
#description: 
nav: true
---

Welcome! Thank you for your interest in working with me. 

Below is a list of research projects that I have been or will be doing. 
If any of them is interesting to you, please send your application to <hongyuan@ttic.edu>. 
Your application should include
- your up-to-date CV; 
- 1~3 contacts for (if needed) reference letters; 
- the specific project(s) that you'd like to work on, and why you like them; 
- a short description about your background and how it has prepared you for the project(s). 

#### Event Sequence Modeling

*Events are everywhere.* They include: 
- *Medical events.* Each patient has a sequence of doctorâ€™s visits, tests, diagnoses, and medications. 
- *Consumer events.* Each online consumer has a sequence of online views and purchases. 
- *Life events.* Some people use smart devices to record their eating, traveling, walking, and sleeping. 
- *Social media events.* Facebook and Twitter users generate posts, shares, comments, and messages. 
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/med-example.jpeg">
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/edu-example.jpeg">
    </div>
</div>
Two examples of event sequences in the medical (left) and educational (right) domains. 

I build *neural probabilistic models* for sequences of events, with which one could *predict the future events given the past*. 
For example, one may probabilistically predict a patient's prognosis, eventual diagnosis, and treatment cost based on their symptoms and treatments so far. 

My past work includes flexible models ([neural Hawkes process](https://arxiv.org/abs/1612.09328) & [neural Datalog through time](https://arxiv.org/abs/2006.16723)) and efficient algorithms ([particle smoothing](https://arxiv.org/abs/1905.05570) & [noise contrastive estimation](https://arxiv.org/abs/2011.00717)). 

Future research directions might be: 
- breaking the limitation of autoregressive neural models (what are they?); 
- exploring data augmentation techniques (what would be the challenges?); 
- ... 

Maybe you can even come up with your own research questions in this area? 

#### Event-Based Reinforcement Learning

to be continued

#### Neural Language Models

to be continued

