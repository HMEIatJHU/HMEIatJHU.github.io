---
---

@string{aps = {American Physical Society,}}

@article{yoneda2023llm, 
  abbr = {arxiv},
  bibtex_show = {true}, 
  title = {Statler: State-Maintaining Language Models for Embodied Reasoning}, 
  author = {Yoneda, Takuma and Fang, Jiading and Li, Peng and Zhang, Huanyu and Jiang, Tianchong and Lin, Shengjie and Picker, Ben and Yunis, David and Mei, Hongyuan and Walter, Matthew R.}, 
  journal = {arXiv preprint}, 
  year = {2023}, 
  arxiv = {2306.17840}, 
  abstract = {
    Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler is its use of two instances of general LLMs -- a world-model reader and a world-model writer -- that interface with and maintain the world state. By providing access to this world state ``memory'', Statler improves the ability of existing LLMs to reason over longer time horizons without the constraint of context length. We evaluate the effectiveness of our approach on three simulated table-top manipulation domains and a real robot domain, and show that it improves the state-of-the-art in LLM-based robot reasoning.
  }
}

@article{tsai2023game, 
  abbr = {arxiv},
  bibtex_show = {true},
  title = {Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions},
  author = {Tsai, Chen Feng and Zhou, Xiaochen and Liu, Sierra S. and Li, Jing and Yu, Mo and Mei, Hongyuan}, 
  journal={arXiv preprint},
  year={2023}, 
  arxiv={2304.02868}, 
  abstract = {
    Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.
  }
}


@article{du2023lookahead, 
  abbr = {arxiv},
  bibtex_show = {true},
  title = {Autoregressive Modeling with Lookahead Attention},
  author = {Du, Li and Mei, Hongyuan and Eisner, Jason}, 
  journal={arXiv preprint},
  year={2023}, 
  arxiv={2305.12272}, 
  abstract = {
    To predict the next token, autoregressive models ordinarily examine the past. Could they also benefit from also examining hypothetical futures? We consider a novel Transformer-based autoregressive architecture that estimates the next-token distribution by extrapolating multiple continuations of the past, according to some proposal distribution, and attending to these extended strings. This architecture draws insights from classical AI systems such as board game players: when making a local decision, a policy may benefit from exploring possible future trajectories and analyzing them. On multiple tasks including morphological inflection and Boolean satisfiability, our lookahead model is able to outperform the ordinary Transformer model of comparable size. However, on some tasks, it appears to be benefiting from the extra computation without actually using the lookahead information. We discuss possible variant architectures as well as future speedups.
  }
}


@inproceedings{zhao2023logic,
  abbr = {EMNLP},
  bibtex_show = {true},
  title = {Explicit Planning Helps Language Models in Logical Reasoning},
  author = {Zhao, Hongyu and Wang, Kangrui and Yu, Mo and Mei, Hongyuan}, 
  booktitle={EMNLP},
  year={2023}, 
  arxiv={2303.15714}, 
  code = {https://github.com/cindermond/leap}, 
  abstract = {
    Language models have been shown to perform remarkably well on a wide range of natural language processing tasks. In this paper, we propose LEAP, a novel system that uses language models to perform multi-step logical reasoning and incorporates explicit planning into the inference procedure. Explicit planning enables the system to make more informed reasoning decisions at each step by looking ahead into their future effects. Moreover, we propose a training strategy that safeguards the planning process from being led astray by spurious features. Our full system significantly outperforms other competing methods on multiple standard datasets. When using small T5 models as its core selection and deduction components, our system performs competitively compared to GPT-3 despite having only about 1B parameters (i.e., 175 times smaller than GPT-3). When using GPT-3.5, it significantly outperforms chain-of-thought prompting on the challenging PrOntoQA dataset. We have conducted extensive empirical studies to demonstrate that explicit planning plays a crucial role in the system's performance.
  }
}


@inproceedings{shi2023abductive, 
  abbr = {NeurIPS}, 
  bibtex_show = {true}, 
  title = {Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning}, 
  author = {Shi, Xiaoming and Xue, Siqiao and Wang, Kangrui and Zhou, Fan and Zhang, James Y. and Zhou, Jun and Tan, Chenhao and Mei, Hongyuan}, 
  code = {https://github.com/iLampard/lamp}, 
  booktitle = {NeurIPS}, 
  year={2023}, 
  arxiv={2305.16646}, 
  abstract = {
    Large language models have shown astonishing performance on a wide range of reasoning tasks. In this paper, we investigate whether they could reason about real-world events and help improve the prediction performance of event sequence models. We design LAMP, a framework that integrates a large language model in event prediction. Particularly, the language model performs abductive reasoning to assist an event sequence model: the event model proposes predictions on future events given the past; instructed by a few expert-annotated demonstrations, the language model learns to suggest possible causes for each proposal; a search module finds out the previous events that match the causes; a scoring function learns to examine whether the retrieved events could actually cause the proposal. Through extensive experiments on several challenging real-world datasets, we demonstrate that our framework---thanks to the reasoning capabilities of large language models---could significantly outperform the state-of-the-art event sequence models. 
  }
}


@inproceedings{gu2023robust, 
  abbr = {ACL},
  bibtex_show = {true},
  title = {Robustness of Learning from Task Instructions},
  author = {Gu, Jiasheng and Zhao, Hongyu and Xu, Hanzi and Nie, Liangyu and Mei, Hongyuan and Yin, Wenpeng}, 
  booktitle = {Findings of ACL},
  year={2023}, 
  arxiv={2212.03813}, 
  abstract = {
    Traditional supervised learning mostly works on individual tasks and requires training on a large set of task-specific examples. This paradigm seriously hinders the development of task generalization since preparing a task-specific example set is costly. To build a system that can quickly and easily generalize to new tasks, task instructions have been adopted as an emerging trend of supervision recently. These instructions give the model the definition of the task and allow the model to output the appropriate answer based on the instructions and inputs. However, task instructions are often expressed in different forms, which can be interpreted from two threads: first, some instructions are short sentences and are pretrained language model (PLM) oriented, such as prompts, while other instructions are paragraphs and are human-oriented, such as those in Amazon MTurk; second, different end-users very likely explain the same task with instructions of different textual expressions. A robust system for task generalization should be able to handle any new tasks regardless of the variability of instructions. However, the system robustness in dealing with instruction-driven task generalization is still unexplored. This work investigates the system robustness when the instructions of new tasks are (i) manipulated, (ii) paraphrased, or (iii) from different levels of conciseness. To our knowledge, this is the first work that systematically studies how robust a PLM is when it is supervised by instructions with different factors of variability.
  }
}


@inproceedings{zhang2023health, 
  abbr = {AISTATS}, 
  bibtex_show={true},
  author = {Zhiyue Zhang and Hongyuan Mei and Yanxun Xu}, 
  title = {Continuous-Time Decision Transformer for Healthcare Applications}, 
  booktitle = {AISTATS}, 
  year = {2023}, 
  code = {https://github.com/ZhiyueZ/CTDT}, 
  abstract = {
    Offline reinforcement learning is a promising approach for training intelligent medical agents to learn treatment policies and assist decision making in many healthcare applications, such as scheduling clinical visits and assigning dosages for patients with chronic conditions. In this paper, we investigate the potential usefulness of Decision Transformer---a new offline reinforcement learning paradigm---in medical domains where decision making in continuous time is desired. As Decision Transformer only handles discrete-time (or, turn-based) sequential decision making scenarios, we generalize it to Continuous-Time Decision Transformer that not only considers the past clinical measurements and treatments but also the timings of previous visits, and learns to suggest the timings of future visits as well as the treatment plan at each visit. Extensive experiments on synthetic datasets and simulators motivated by real-world medical applications demonstrate that Continuous-Time Decision Transformer is able to outperform competitors and has clinical utility in terms of improving patients' health and prolonging their survival by learning high-performance policies from logged data generated using policies of different levels of quality.
  }
}


@inproceedings{qu2023bellman,
  abbr = {AAAI}, 
  bibtex_show={true},
  title={Bellman Meets {H}awkes: Model-Based Reinforcement Learning via Temporal Point Processes},
  author={Qu, Chao and Tan, Xiaoyu and Xue, Siqiao and Shi, Xiaoming and Zhang, James and Mei, Hongyuan},
  booktitle = {AAAI},
  year={2023}, 
  arxiv = {2201.12569}, 
  code = {https://github.com/Event-Driven-rl/Event-Driven-RL}, 
  abstract={
    We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agent's actions and observations are asynchronous stochastic discrete events occurring in continuous-time. We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method in both synthetic simulator and real-world problem.
  }
}


@inproceedings{zhao2022tiny,
  abbr = {EMNLP},
  bibtex_show={true},
  author =      {Hongyu Zhao and Hao Tan and Hongyuan Mei},
  title =       {Tiny-Attention Adapter: Contexts Are More Important Than the Number of Parameters},
  booktitle =   {EMNLP},
  year =        {2022}, 
  arxiv = {2211.01979}, 
  code = {https://github.com/cindermond/tiny-attn}, 
  abstract={
    Adapter-tuning is a paradigm that transfers a pretrained language model to downstream tasks by adding and tuning a small number of new parameters. Previously proposed adapter architectures are all feed-forward neural networks. In this paper, we investigate the effectiveness of using tiny-attention -- i.e., attention with extremely small per-head dimensionality -- as adapters. Our tiny-attention adapter learns to modify the hidden states at each position directly conditioned on the hidden states at all the other positions, which is missed by the previously proposed adapters. Moreover, we view its multiple attention heads as a mixture of experts and propose to average their weights during deployment, which further reduces its inference computation cost. On the GLUE benchmark, our tiny-attention adapter outperforms the other parameter-efficient transfer learning methods as well as full fine-tuning while only updating 0.05% of the parameters. On the FewGLUE benchmark, its performance is comparable to that of GPT-3 and PET.
  }
}

@inproceedings{xie2022nc,
  abbr = {EMNLP},
  bibtex_show={true},
  author =      {Shuo Xie and Jiahao Qiu and Ankita Pasad and Li Du and Qing Qu and Hongyuan Mei},
  title =       {Hidden State Variability of Pretrained Language Models Can Guide Computation Reduction for Transfer Learning},
  booktitle =   {Findings of EMNLP},
  year =        {2022}, 
  arxiv = {2210.10041}, 
  code = {https://github.com/shuox20/variability-efficient-tuning}, 
  abstract={
    While transferring a pretrained language model, common approaches conventionally attach their task-specific classifiers to the top layer and adapt all the pretrained layers. We investigate whether one could make a task-specific selection on which subset of the layers to adapt and where to place the classifier. The goal is to reduce the computation cost of transfer learning methods (e.g. fine-tuning or adapter-tuning) without sacrificing its performance.
   
    We propose to select layers based on the variability of their hidden states given a task-specific corpus. We say a layer is already "well-specialized" in a task if the within-class variability of its hidden states is low relative to the between-class variability. Our variability metric is cheap to compute and doesn't need any training or hyperparameter tuning. It is robust to data imbalance and data scarcity. Extensive experiments on the GLUE benchmark demonstrate that selecting layers based on our metric can yield significantly stronger performance than using the same number of top layers and often match the performance of fine-tuning or adapter-tuning the entire language model.
  }
}

@inproceedings{xue2022hypro,
  abbr = {NeurIPS},
  bibtex_show={true},
  author =      {Siqiao Xue and Xiaoming Shi and James Y Zhang and Hongyuan Mei},
  title =       {HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences},
  booktitle =   {NeurIPS},
  year =        {2022}, 
  arxiv = {2210.01753}, 
  code = {https://github.com/iLampard/hypro_tpp}, 
  abstract={
    In this paper, we tackle the important yet under-investigated problem of making long-horizon prediction of event sequences. Existing state-of-the-art models do not perform well at this task due to their autoregressive structure. We propose HYPRO, a hybridly normalized probabilistic model that naturally fits this task: its first part is an autoregressive base model that learns to propose predictions; its second part is an energy function that learns to reweight the proposals such that more realistic predictions end up with higher probabilities. We also propose efficient training and inference algorithms for this model. Experiments on multiple real-world datasets demonstrate that our proposed HYPRO model can significantly outperform previous models at making long-horizon predictions of future events. We also conduct a range of ablation studies to investigate the effectiveness of each component of our proposed methods.
  }
}


@inproceedings{yang2022andtt,
  abbr = {ICLR},
  bibtex_show={true},
  author =      {Chenghao Yang and Hongyuan Mei and Jason Eisner},
  title =       {Transformer Embeddings of Irregularly Spaced Events and Their Participants},
  booktitle =   {ICLR},
  year =        {2022}, 
  arxiv = {2201.00044}, 
  code = {https://github.com/yangalan123/anhp-andtt}, 
  abstract={
    We propose an approach to modeling irregularly spaced sequences of discrete events. We begin with a continuous-time variant of the Transformer, which was originally formulated (Vaswani et al., 2017) for sequences without timestamps. We embed a possible event (or other boolean fact) at time t by using attention over the events that occurred at times < t (and the facts that were true when they occurred). We control this attention using pattern-matching logic rules that relate events and facts that share participants. These rules determine which previous events will be attended to, as well as how to transform the embeddings of the events and facts into the attentional queries, keys, and values. Other logic rules describe how to change the set of facts in response to events. Our approach closely follows Mei et al. (2020a), and adopts their Datalog Through Time formalism for logic rules. As in that work, a domain expert first writes a set of logic rules that establishes the set of possible events and other facts at each time t. Each possible event or other fact is embedded using a neural architecture that is derived from the rules that established it. Our only difference from Mei et al. (2020a) is that we derive a flatter, attention-based neural architecture whereas they used a more serial LSTM architecture. We find that our attention-based approach performs about equally well on the RoboCup dataset, where the logic rules play an important role in improving performance. We also compared these two methods with two previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a) on simpler synthetic and real domains without logic rules, and found our proposed approach to be at least as good, and sometimes better, than each of the other three methods.
  }
}

@article{hua2022personalized,
  abbr = {BA},
  bibtex_show = {true},
  title = {Personalized Dynamic Treatment Regimes in Continuous Time: A {B}ayesian Joint Model for Optimizing Clinical Decisions with Timing},
  author = {Hua, William and Mei, Hongyuan and Zohar, Sarah and Giral, Magali and Xu, Yanxun},
  journal={Bayesian Analysis},
  year={2022}, 
  arxiv={2007.04155}, 
  code = {https://github.com/YanxunXu/doct}, 
  abstract = {
    Accurate models of clinical actions and their impacts on disease progression are critical for estimating personalized optimal dynamic treatment regimes (DTRs) in medical/health research, especially in managing chronic conditions. Traditional statistical methods for DTRs usually focus on estimating the optimal treatment or dosage at each given medical intervention, but overlook the important question of "when this intervention should happen." We fill this gap by developing a two-step Bayesian approach to optimize clinical decisions with timing. In the first step, we build a generative model for a sequence of medical interventions-which are discrete events in continuous time-with a marked temporal point process (MTPP) where the mark is the assigned treatment or dosage. Then this clinical action model is embedded into a Bayesian joint framework where the other components model clinical observations including longitudinal medical measurements and time-to-event data conditional on treatment histories. In the second step, we propose a policy gradient method to learn the personalized optimal clinical decision that maximizes the patient survival by interacting the MTPP with the model on clinical observations while accounting for uncertainties in clinical observations learned from the posterior inference of the Bayesian joint model in the first step. A signature application of the proposed approach is to schedule follow-up visitations and assign a dosage at each visitation for patients after kidney transplantation. We evaluate our approach with comparison to alternative methods on both simulated and real-world datasets. In our experiments, the personalized decisions made by the proposed method are clinically useful: they are interpretable and successfully help improve patient survival.
  }
}

@inproceedings{mei2020nce,
  abbr = {NeurIPS},
  bibtex_show={true},
  author =      {Hongyuan Mei and Tom Wan and Jason Eisner},
  title =       {Noise-Contrastive Estimation for Multivariate Point Processes},
  booktitle =   {NeurIPS},
  year =        {2020}, 
  arxiv = {2011.00717}, 
  code = {https://github.com/HMEIatJHU/nce-mpp}, 
  talk = {https://youtu.be/2GkZfl9NtO0}, 
  slides = {mei+wan+eisner.neurips20.talk.pdf}, 
  abstract={
    The log-likelihood of a generative model often involves both positive and negative terms. For a temporal multivariate point process, the negative term sums over all the possible event types at each time and also integrates over all the possible times. As a result, maximum likelihood estimation is expensive. We show how to instead apply a version of noise-contrastive estimation---a general parameter estimation method with a less expensive stochastic objective. Our specific instantiation of this general idea works out in an interestingly non-trivial way and has provable guarantees for its optimality, consistency and efficiency. On several synthetic and real-world datasets, our method shows benefits: for the model to achieve the same level of log-likelihood on held-out data, our method needs considerably fewer function evaluations and less wall-clock time.
  }
}

@inproceedings{mei2020datalog,
  abbr = {ICML},
  bibtex_show={true},
  author =      {Hongyuan Mei and Guanghui Qin and Minjie Xu and Jason Eisner},
  title =       {Neural {D}atalog Through Time: {I}nformed Temporal Modeling via Logical Specification},
  booktitle =   {ICML},
  year =        {2020},
  arxiv = {2006.16723}, 
  code = {https://github.com/HMEIatJHU/neural-datalog-through-time}, 
  talk = {https://youtu.be/mp79uOO5ZuA}, 
  slides = {mei+qin+xu+eisner.icml20.talk.pdf}, 
  abstract={
    Learning how to predict future events from patterns of past events is difficult when the set of possible event types is large. Training an unrestricted neural model might overfit to spurious patterns. To exploit domain-specific knowledge of how past events might affect an event's present probability, we propose using a temporal deductive database to track structured facts over time. Rules serve to prove facts from other facts and from past events. Each fact has a time-varying state---a vector computed by a neural net whose topology is determined by the fact's provenance, including its experience of past events. The possible event types at any time are given by special facts, whose probabilities are neurally modeled alongside their states. In both synthetic and real-world domains, we show that neural probabilistic models derived from concise Datalog programs improve prediction by encoding appropriate domain knowledge in their architecture.
  }
}

@inproceedings{mei2019smoothing,
  abbr = {ICML},
  bibtex_show={true},
  author =      {Hongyuan Mei and Guanghui Qin and Jason Eisner},
  title =       {Imputing Missing Events in Continuous-Time Event Streams},
  booktitle =   {ICML},
  year =        {2019},
  arxiv = {1905.05570}, 
  code = {https://github.com/HMEIatJHU/neural-hawkes-particle-smoothing}, 
  poster = {mei+qin+eisner.icml19.poster.pdf}, 
  slides = {mei+qin+eisner.icml19.talk.pdf}, 
  abstract={
    Events in the world may be caused by other, unobserved events. We consider sequences of events in continuous time. Given a probability model of complete sequences, we propose particle smoothing---a form of sequential importance sampling---to impute the missing events in an incomplete sequence. We develop a trainable family of proposal distributions based on a type of bidirectional continuous-time LSTM: Bidirectionality lets the proposals condition on future observations, not just on the past as in particle filtering. Our method can sample an ensemble of possible complete sequences (particles), from which we form a single consensus prediction that has low Bayes risk under our chosen loss metric. We experiment in multiple synthetic and real domains, using different missingness mechanisms, and modeling the complete sequences in each domain with a neural Hawkes process (Mei & Eisner 2017). On held-out incomplete sequences, our method is effective at inferring the ground-truth unobserved events, with particle smoothing consistently improving upon particle filtering.
  }
}

@inproceedings{mei2017neuralhawkes,
  abbr = {NeurIPS},
  bibtex_show = {true},
  author =      {Hongyuan Mei and Jason Eisner},
  title =       {The Neural {H}awkes Process: {A} Neurally Self-Modulating Multivariate Point Process},
  booktitle =   {NeurIPS},
  year =        {2017},
  arxiv = {1612.09328}, 
  code = {https://github.com/HMEIatJHU/neurawkes}, 
  talk = {https://youtu.be/G7JfYnSlKUM}, 
  poster = {mei+eisner.nips17.poster.pdf},
  abstract={
    Many events occur in the world. Some event types are stochastically excited or inhibited---in the sense of having their probabilities elevated or decreased---by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions.
  }
}

@inproceedings{mei2019classifier,
  abbr = {NAACL},
  bibtex_show = {true},
  author =      {Shijia Liu and Hongyuan Mei and Adina Williams and Ryan Cotterell},
  title =       {On the Idiosyncrasies of the {M}andarin {C}hinese Classifier System},
  booktitle = {NAACL},
  year =        {2019},
  arxiv = {1902.10193}, 
  abstract={
    While idiosyncrasies of the Chinese classifier system have been a richly studied topic among linguists (Adams and Conklin, 1973; Erbaugh, 1986; Lakoff, 1986), not much work has been done to quantify them with statistical methods. In this paper, we introduce an information-theoretic approach to measuring idiosyncrasy; we examine how much the uncertainty in Mandarin Chinese classifiers can be reduced by knowing semantic information about the nouns that the classifiers modify. Using the empirical distribution of classifiers from the parsed Chinese Gigaword corpus (Graff et al., 2005), we compute the mutual information (in bits) between the distribution over classifiers and distributions over other linguistic quantities. We investigate whether semantic classes of nouns and adjectives differ in how much they reduce uncertainty in classifier choice, and find that it is not fully idiosyncratic; while there are no obvious trends for the majority of semantic classes, shape nouns reduce uncertainty in classifier choice the most.
  }
}

@inproceedings{mei2018halo,
  abbr = {*SEM},
  bibtex_show = {true},
  author =      {Hongyuan Mei* and Sheng Zhang* and Kevin Duh and Benjamin Van Durme},
  title =       {Halo: Learning Semantics-Aware Representations for Cross-Lingual Information Extraction},
  booktitle =   {Joint Conference on Lexical and Computational Semantics},
  year =        {2018},
  arxiv = {1805.08271}, 
  abstract={
    Cross-lingual information extraction (CLIE) is an important and challenging task, especially in low resource scenarios. To tackle this challenge, we propose a training method, called Halo, which enforces the local region of each hidden state of a neural model to only generate target tokens with the same semantic structure tag. This simple but powerful technique enables a neural model to learn semantics-aware representations that are robust to noise, without introducing any extra parameter, thus yielding better generalization in both high and low resource settings.
  }
}

@inproceedings{mei2017coherent,
  abbr = {AAAI},
  bibtex_show = {true},
  title     = {Coherent Dialogue with Attention-based Language Models},
  author    = {Hongyuan Mei and Mohit Bansal and Matthew R. Walter},
  booktitle = {AAAI},
  year      = {2017}, 
  arxiv = {1611.06997}, 
  abstract = {
    We model coherent conversation continuation via RNN-based dialogue models equipped with a dynamic attention mechanism. Our attention-RNN language model dynamically increases the scope of attention on the history as the conversation continues, as opposed to standard attention (or alignment) models with a fixed input scope in a sequence-to-sequence model. This allows each generated word to be associated with the most relevant words in its corresponding conversation history. We evaluate the model on two popular dialogue datasets, the open-domain MovieTriples dataset and the closed-domain Ubuntu Troubleshoot dataset, and achieve significant improvements over the state-of-the-art and baselines on several metrics, including complementary diversity-based metrics, human evaluation, and qualitative visualizations. We also show that a vanilla RNN with dynamic attention outperforms more complex memory models (e.g., LSTM and GRU) by allowing for flexible, long-distance memory. We promote further coherence via topic modeling-based reranking.
  }
}

@inproceedings{mei2016selective,
  abbr = {NAACL},
  bibtex_show = {true},
  title     = {What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment},
  author    = {Hongyuan Mei and Mohit Bansal and Matthew R. Walter},
  booktitle = {NAACL},
  year      = {2016}, 
  arxiv = {1509.00838}, 
  code = {https://github.com/HMEIatJHU/SelectiveGeneration}, 
  abstract = {
    We propose an end-to-end, domain-independent neural encoder-aligner-decoder model for selective generation, i.e., the joint task of content selection and surface realization. Our model first encodes a full set of over-determined database event records via an LSTM-based recurrent neural network, then utilizes a novel coarse-to-fine aligner to identify the small subset of salient records to talk about, and finally employs a decoder to generate free-form descriptions of the aligned, selected records. Our model achieves the best selection and generation results reported to-date (with 59% relative improvement in generation) on the benchmark WeatherGov dataset, despite using no specialized features or linguistic resources. Using an improved k-nearest neighbor beam filter helps further. We also perform a series of ablations and visualizations to elucidate the contributions of our key model components. Lastly, we evaluate the generalizability of our model on the RoboCup dataset, and get results that are competitive with or better than the state-of-the-art, despite being severely data-starved.
  }
}

@inproceedings{mei2016navigational,
  abbr = {AAAI},
  bibtex_show = {true},
  title     = {Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences},
  author    = {Hongyuan Mei and Mohit Bansal and Matthew R. Walter},
  booktitle = {AAAI},
  year      = {2016}, 
  arxiv = {1506.04089}, 
  code = {https://github.com/HMEIatJHU/NeuralWalker}, 
  abstract = {
    We propose a neural sequence-to-sequence model for direction following, a task that is essential to realizing effective autonomous agents. Our alignment-based encoder-decoder model with long short-term memory recurrent neural networks (LSTM-RNN) translates natural language instructions to action sequences based upon a representation of the observable world state. We introduce a multi-level aligner that empowers our model to focus on sentence "regions" salient to the current world state by using multiple abstractions of the input sentence. In contrast to existing methods, our model uses no specialized linguistic resources (e.g., parsers) or task-specific annotations (e.g., seed lexicons). It is therefore generalizable, yet still achieves the best results reported to-date on a benchmark single-sentence dataset and competitive results for the limited-training multi-sentence setting. We analyze our model through a series of ablations that elucidate the contributions of the primary components of our model.
  }
}

@article{chu2015satellite,
  abbr = {NeurIPS},
  bibtex_show = {true},
  title={Accurate Vision-based Vehicle Localization using Satellite Imagery},
  author={Hang Chu and Hongyuan Mei and Mohit Bansal and Matthew R. Walter},
  journal={arXiv preprint arXiv: 1510.09171},
  year={2015}, 
  arxiv = {1510.09171}, 
  abstract = {
    We propose a method for accurately localizing ground vehicles with the aid of satellite imagery. Our approach takes a ground image as input, and outputs the location from which it was taken on a georeferenced satellite image. We perform visual localization by estimating the co-occurrence probabilities between the ground and satellite images based on a ground-satellite feature dictionary. The method is able to estimate likelihoods over arbitrary locations without the need for a dense ground image database. We present a ranking-loss based algorithm that learns location-discriminative feature projection matrices that result in further improvements in accuracy. We evaluate our method on the Malaga and KITTI public datasets and demonstrate significant improvements over a baseline that performs exhaustive search.
  }
}
